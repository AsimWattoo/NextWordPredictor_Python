{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences, to_categorical\n",
    "from tensorflow.keras.layers import Dense, InputLayer, GRU, LSTM, Embedding, Bidirectional, Flatten\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "with open(\"Dataset.txt\", 'r') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8922"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(oov_token='OOV')\n",
    "tokenizer.fit_on_texts([text])\n",
    "word_index = tokenizer.word_index\n",
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580614\n",
      "559814\n"
     ]
    }
   ],
   "source": [
    "# Filtering the text to create n-ragged sequences\n",
    "print(len(text))\n",
    "new_text = text.replace('_', ' ')\n",
    "new_text = new_text.replace('.', '')\n",
    "new_text = new_text.replace(',', '')\n",
    "new_text = new_text.replace('!', '')\n",
    "new_text = new_text.replace('$', '')\n",
    "new_text = new_text.replace('-', '')\n",
    "new_text = new_text.replace('(', '')\n",
    "new_text = new_text.replace(')', '')\n",
    "new_text = new_text.replace('  ', ' ')\n",
    "new_text = new_text.replace('“', '')\n",
    "new_text = new_text.replace('”', '')\n",
    "print(len(new_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8811"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_text = []\n",
    "for x in new_text.split('\\n'):\n",
    "    if len(x) >= 20:\n",
    "        final_text.append(x)\n",
    "\n",
    "len(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96973"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizing the sequence\n",
    "sequences = tokenizer.texts_to_sequences(final_text)\n",
    "n_ragged_sequences = []\n",
    "# Creating n-ragged sequences\n",
    "for sequence in sequences:\n",
    "    for i in range(len(sequence) - 1):\n",
    "        new_sequence = sequence[0:i+2]\n",
    "        n_ragged_sequences.append(new_sequence)\n",
    "len(n_ragged_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Padding the sequences\n",
    "padded_sequences = pad_sequences(n_ragged_sequences, padding='pre')\n",
    "padded_sequences = np.array(padded_sequences)\n",
    "max_length = len(padded_sequences[0])\n",
    "max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96973, 17), (96973, 8923))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = padded_sequences[:, :-1]\n",
    "y = padded_sequences[:, -1]\n",
    "y = to_categorical(y)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset in training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((87275, 87275), (9698, 9698))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and Testing Sizes\n",
    "(len(X_train), len(y_train)), (len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(word_index) + 1\n",
    "epochs = 20\n",
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 17, 100)           892300    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                42240     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8923)              579995    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,514,535\n",
      "Trainable params: 1,514,535\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(num_labels, 100, input_length=max_length - 1, ),\n",
    "    LSTM(units= 64),\n",
    "    Dense(units= num_labels, activation= 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32md:\\Work\\Programming\\Jupyter\\NextWordPredictor\\Predictor.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Work/Programming/Jupyter/NextWordPredictor/Predictor.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m checkpoint \u001b[39m=\u001b[39m ModelCheckpoint(filepath\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpredictor.h5\u001b[39m\u001b[39m'\u001b[39m, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, save_weights_only\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m, save_freq\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Work/Programming/Jupyter/NextWordPredictor/Predictor.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test), validation_batch_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[checkpoint])\n",
      "File \u001b[1;32md:\\Applications\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\Applications\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(filepath= 'predictor.h5', monitor='val_loss', save_best_only=True, save_weights_only=False, mode='min', save_freq='epoch')\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=1, validation_data=(X_test, y_test), validation_batch_size=1, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1693/3351 [==============>...............] - ETA: 5s"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential/dense_8/Softmax' defined at (most recent call last):\n    File \"d:\\Applications\\Anaconda\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"d:\\Applications\\Anaconda\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"d:\\Applications\\Anaconda\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"d:\\Applications\\Anaconda\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"d:\\Applications\\Anaconda\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\asimw\\AppData\\Local\\Temp\\ipykernel_25724\\4158841612.py\", line 1, in <module>\n      predictions = np.argmax(model.predict(X), 0)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\layers\\core\\dense.py\", line 255, in call\n      outputs = self.activation(outputs)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\activations.py\", line 84, in softmax\n      output = tf.nn.softmax(x, axis=axis)\nNode: 'sequential/dense_8/Softmax'\nOOM when allocating tensor with shape[32,9281] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential/dense_8/Softmax}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_202115]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32md:\\Work\\Programming\\Jupyter\\NextWordPredictor\\Predictor.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Work/Programming/Jupyter/NextWordPredictor/Predictor.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(model\u001b[39m.\u001b[39;49mpredict(X), \u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32md:\\Applications\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\Applications\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential/dense_8/Softmax' defined at (most recent call last):\n    File \"d:\\Applications\\Anaconda\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"d:\\Applications\\Anaconda\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"d:\\Applications\\Anaconda\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"d:\\Applications\\Anaconda\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"d:\\Applications\\Anaconda\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\asimw\\AppData\\Local\\Temp\\ipykernel_25724\\4158841612.py\", line 1, in <module>\n      predictions = np.argmax(model.predict(X), 0)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\layers\\core\\dense.py\", line 255, in call\n      outputs = self.activation(outputs)\n    File \"d:\\Applications\\Anaconda\\lib\\site-packages\\keras\\activations.py\", line 84, in softmax\n      output = tf.nn.softmax(x, axis=axis)\nNode: 'sequential/dense_8/Softmax'\nOOM when allocating tensor with shape[32,9281] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential/dense_8/Softmax}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_202115]"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(model.predict(X), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0th Example\n",
      "Actual:  To Sherlock Holland she is\n",
      "Predicted:  To Sherlock Holland she intrusions\n",
      "\n",
      "\n",
      "1th Example\n",
      "Actual:  Sherlock Holland she is always\n",
      "Predicted:  Sherlock Holland she is intrusions\n",
      "\n",
      "\n",
      "2th Example\n",
      "Actual:  Holland she is always the\n",
      "Predicted:  Holland she is always intrusions\n",
      "\n",
      "\n",
      "3th Example\n",
      "Actual:  she is always the woman\n",
      "Predicted:  she is always the intrusions\n",
      "\n",
      "\n",
      "4th Example\n",
      "Actual:  is always the woman I\n",
      "Predicted:  is always the woman intrusions\n",
      "\n",
      "\n",
      "5th Example\n",
      "Actual:  always the woman I hauling\n",
      "Predicted:  always the woman I intrusions\n",
      "\n",
      "\n",
      "6th Example\n",
      "Actual:  the woman I hauling seldom\n",
      "Predicted:  the woman I hauling intrusions\n",
      "\n",
      "\n",
      "7th Example\n",
      "Actual:  woman I hauling seldom heard\n",
      "Predicted:  woman I hauling seldom intrusions\n",
      "\n",
      "\n",
      "8th Example\n",
      "Actual:  I hauling seldom heard him\n",
      "Predicted:  I hauling seldom heard intrusions\n",
      "\n",
      "\n",
      "9th Example\n",
      "Actual:  hauling seldom heard him mention\n",
      "Predicted:  hauling seldom heard him intrusions\n",
      "\n",
      "\n",
      "10th Example\n",
      "Actual:  seldom heard him mention her\n",
      "Predicted:  seldom heard him mention intrusions\n",
      "\n",
      "\n",
      "11th Example\n",
      "Actual:  heard him mention her under\n",
      "Predicted:  heard him mention her intrusions\n",
      "\n",
      "\n",
      "12th Example\n",
      "Actual:  him mention her under any\n",
      "Predicted:  him mention her under intrusions\n",
      "\n",
      "\n",
      "13th Example\n",
      "Actual:  mention her under any other\n",
      "Predicted:  mention her under any intrusions\n",
      "\n",
      "\n",
      "14th Example\n",
      "Actual:  her under any other name\n",
      "Predicted:  her under any other intrusions\n",
      "\n",
      "\n",
      "15th Example\n",
      "Actual:  under any other name In\n",
      "Predicted:  under any other name intrusions\n",
      "\n",
      "\n",
      "16th Example\n",
      "Actual:  any other name In his\n",
      "Predicted:  any other name In intrusions\n",
      "\n",
      "\n",
      "17th Example\n",
      "Actual:  other name In his eyes\n",
      "Predicted:  other name In his intrusions\n",
      "\n",
      "\n",
      "18th Example\n",
      "Actual:  name In his eyes she\n",
      "Predicted:  name In his eyes intrusions\n",
      "\n",
      "\n",
      "19th Example\n",
      "Actual:  In his eyes she eclipses\n",
      "Predicted:  In his eyes she intrusions\n",
      "\n",
      "\n",
      "20th Example\n",
      "Actual:  his eyes she eclipses and\n",
      "Predicted:  his eyes she eclipses intrusions\n",
      "\n",
      "\n",
      "21th Example\n",
      "Actual:  eyes she eclipses and predominates\n",
      "Predicted:  eyes she eclipses and intrusions\n",
      "\n",
      "\n",
      "22th Example\n",
      "Actual:  she eclipses and predominates the\n",
      "Predicted:  she eclipses and predominates intrusions\n",
      "\n",
      "\n",
      "23th Example\n",
      "Actual:  eclipses and predominates the whole\n",
      "Predicted:  eclipses and predominates the intrusions\n",
      "\n",
      "\n",
      "24th Example\n",
      "Actual:  and predominates the whole of\n",
      "Predicted:  and predominates the whole intrusions\n",
      "\n",
      "\n",
      "25th Example\n",
      "Actual:  predominates the whole of her\n",
      "Predicted:  predominates the whole of intrusions\n",
      "\n",
      "\n",
      "26th Example\n",
      "Actual:  the whole of her sex\n",
      "Predicted:  the whole of her intrusions\n",
      "\n",
      "\n",
      "27th Example\n",
      "Actual:  whole of her sex It\n",
      "Predicted:  whole of her sex intrusions\n",
      "\n",
      "\n",
      "28th Example\n",
      "Actual:  of her sex It was\n",
      "Predicted:  of her sex It intrusions\n",
      "\n",
      "\n",
      "29th Example\n",
      "Actual:  her sex It was not\n",
      "Predicted:  her sex It was intrusions\n",
      "\n",
      "\n",
      "30th Example\n",
      "Actual:  sex It was not that\n",
      "Predicted:  sex It was not intrusions\n",
      "\n",
      "\n",
      "31th Example\n",
      "Actual:  It was not that he\n",
      "Predicted:  It was not that intrusions\n",
      "\n",
      "\n",
      "32th Example\n",
      "Actual:  was not that he felt\n",
      "Predicted:  was not that he intrusions\n",
      "\n",
      "\n",
      "33th Example\n",
      "Actual:  not that he felt any\n",
      "Predicted:  not that he felt intrusions\n",
      "\n",
      "\n",
      "34th Example\n",
      "Actual:  that he felt any emotion\n",
      "Predicted:  that he felt any intrusions\n",
      "\n",
      "\n",
      "35th Example\n",
      "Actual:  he felt any emotion akin\n",
      "Predicted:  he felt any emotion intrusions\n",
      "\n",
      "\n",
      "36th Example\n",
      "Actual:  felt any emotion akin to\n",
      "Predicted:  felt any emotion akin intrusions\n",
      "\n",
      "\n",
      "37th Example\n",
      "Actual:  any emotion akin to love\n",
      "Predicted:  any emotion akin to intrusions\n",
      "\n",
      "\n",
      "38th Example\n",
      "Actual:  emotion akin to love for\n",
      "Predicted:  emotion akin to love intrusions\n",
      "\n",
      "\n",
      "39th Example\n",
      "Actual:  akin to love for Irene\n",
      "Predicted:  akin to love for intrusions\n",
      "\n",
      "\n",
      "40th Example\n",
      "Actual:  to love for Irene Adler\n",
      "Predicted:  to love for Irene intrusions\n",
      "\n",
      "\n",
      "41th Example\n",
      "Actual:  love for Irene Adler All\n",
      "Predicted:  love for Irene Adler intrusions\n",
      "\n",
      "\n",
      "42th Example\n",
      "Actual:  for Irene Adler All emotions\n",
      "Predicted:  for Irene Adler All intrusions\n",
      "\n",
      "\n",
      "43th Example\n",
      "Actual:  Irene Adler All emotions and\n",
      "Predicted:  Irene Adler All emotions intrusions\n",
      "\n",
      "\n",
      "44th Example\n",
      "Actual:  Adler All emotions and that\n",
      "Predicted:  Adler All emotions and intrusions\n",
      "\n",
      "\n",
      "45th Example\n",
      "Actual:  All emotions and that one\n",
      "Predicted:  All emotions and that intrusions\n",
      "\n",
      "\n",
      "46th Example\n",
      "Actual:  emotions and that one particularly\n",
      "Predicted:  emotions and that one intrusions\n",
      "\n",
      "\n",
      "47th Example\n",
      "Actual:  and that one particularly were\n",
      "Predicted:  and that one particularly intrusions\n",
      "\n",
      "\n",
      "48th Example\n",
      "Actual:  that one particularly were abhorrent\n",
      "Predicted:  that one particularly were intrusions\n",
      "\n",
      "\n",
      "49th Example\n",
      "Actual:  one particularly were abhorrent to\n",
      "Predicted:  one particularly were abhorrent intrusions\n"
     ]
    }
   ],
   "source": [
    "for j in range(50):\n",
    "    sentence = \"\"\n",
    "    index = j\n",
    "    print(f'\\n\\n{j}th Example')\n",
    "    for num in X[index]:\n",
    "        sentence += f' {unique_words[int(num * max_character)]}'\n",
    "    print(f'Actual: {sentence} {unique_words[int(y[index] * max_character)]}')\n",
    "    print(f'Predicted: {sentence} {unique_words[int(predictions[index] * max_character)]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
